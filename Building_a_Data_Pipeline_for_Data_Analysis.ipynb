{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFcU8yxQweZKBC4pb5ooCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanEwanDalton/Building_A_Data_Pipeline/blob/main/Building_a_Data_Pipeline_for_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 - Data Sourcing\n",
        "\n",
        "---\n",
        "\n",
        "Identify all sources of data your company uses. This may include:\n",
        "\n",
        "1.   Ads - Google ads, social media ads, web traffic\n",
        "2.   Relational databases\n",
        "3.   Streaming data\n",
        "4.   APIs & web scraping\n",
        "5.   Payment and finance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hk2f0G2-iz_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 - Data Extraction & Load\n",
        "\n",
        "---\n",
        "\n",
        "Extract and load all data sources together. Such tools exist that can assist with this, such as:\n",
        "\n",
        "1.   Software as a Service (SaaS) tools - software is structured without individual manipulation\n",
        "2.   Open source tools - software can be manipulated to suit individual/company needs \n",
        "3.   Internal scripts - scripts fully coded by individual/company\n"
      ],
      "metadata": {
        "id": "gozH2otJkvOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 - Data Transformation\n",
        "\n",
        "---\n",
        "Transform the raw data from your sources to enriched data. This involves: \n",
        "\n",
        "1.   Cleaning the raw data into clean data ready to be loaded into a data warehouse\n",
        "2.   Typically for data analytics, cleaned, processed data is stored into a data warehouse. If choosing to store unprocessed, raw data, a data lake is used. This could be a storage location for raw data to be used in future machine learning analytics\n",
        "\n"
      ],
      "metadata": {
        "id": "29bcLh80pE6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 - Data Storage\n",
        "\n",
        "---\n",
        "Store the processed data in a warehouse which can be used for future analytics extraction.\n"
      ],
      "metadata": {
        "id": "DYqPZWQFuIST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 - KPI Creation\n",
        "\n",
        "---\n",
        "Discuss with company teams to identify key performance indicators that the analytics team can use to create workable dashboards. \n"
      ],
      "metadata": {
        "id": "VC5Us2Q1urIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6 - Analytics Dashboard Creation\n",
        "\n",
        "\n",
        "---\n",
        "Create dashboards using analytics tools in order to provide answers to KPIs. \n"
      ],
      "metadata": {
        "id": "YsacMhelvWXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7 - Implementing Reverse 'Extract Transform Load'\n",
        "\n",
        "---\n",
        "Insights derived from analytics and enriched data can be used in previous stages, such as data sourcing, in order to provide improved data sourcing techniques and/or specific data to look for. \n"
      ],
      "metadata": {
        "id": "YiJug81Avypm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8 - Implementing Automation Tools\n",
        "\n",
        "---\n",
        "Once the basic data pipeline is built and functioning, you can explore different automation tools to assist with streamlining important processes and optimise time utilisation. \n"
      ],
      "metadata": {
        "id": "ddnrAgi57JCE"
      }
    }
  ]
}